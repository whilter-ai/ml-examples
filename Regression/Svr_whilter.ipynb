{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Support Vector Regression**"
      ],
      "metadata": {
        "id": "jl6xL8nNSkoq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Importing Libraries**"
      ],
      "metadata": {
        "id": "3mJfAcWaSpA2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y-_TykwJGunW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Loading Dataset**"
      ],
      "metadata": {
        "id": "wawije8TTIhl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/Salary_Data_Based_country_and_race.csv\")"
      ],
      "metadata": {
        "id": "Nznvj0CsI-I3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "OsgPakBHJJ2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Cleaning**"
      ],
      "metadata": {
        "id": "pFylPBL_TPyy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 2.3 Cleaning: drop duplicates, trim whitespace\n",
        "df = df.drop_duplicates().apply(lambda s: s.str.strip() if s.dtype == \"object\" else s)\n",
        "df = df.dropna(subset=[\"Salary\"]).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "lfdkilE-JRq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "n8OjhjUpJa2k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3.1 Rename columns for consistency\n",
        "df = df.rename(columns={\n",
        "    \"Education Level\": \"Education\",\n",
        "    \"Years of Experience\": \"Experience\"\n",
        "})\n",
        "df.columns\n"
      ],
      "metadata": {
        "id": "Fxyr_5a0Jcrq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **EDA and Visulaization**"
      ],
      "metadata": {
        "id": "vuBzjmOOTaPR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 4.1 Distribution of Salary\n",
        "sns.histplot(df[\"Salary\"], kde=True)\n",
        "plt.title(\"Salary Distribution\")\n",
        "plt.show()\n",
        "\n",
        "# 4.2 Salary vs. Experience\n",
        "# sns.scatterplot(x=\"Experience\", y=\"Salary\", data=df)\n",
        "# plt.title(\"Experience vs Salary\")\n",
        "# plt.show()\n"
      ],
      "metadata": {
        "id": "G2emwxmlJptz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.scatterplot(x=\"Experience\", y=\"Salary\", data=df)\n",
        "plt.title(\"Experience vs Salary\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "165_-9w9Jzyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# ohe = OneHotEncoder(drop=\"first\", sparse_output=False)\n",
        "# X_cat = pd.DataFrame(\n",
        "#     ohe.fit_transform(df[cat_cols]),\n",
        "#     columns=ohe.get_feature_names_out(cat_cols),\n",
        "#     index=df.index\n",
        "# )\n"
      ],
      "metadata": {
        "id": "Z96F37WMJsS_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Feature Engineering**\n"
      ],
      "metadata": {
        "id": "rF-VpjY4TpRJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Assume df is already your cleaned DataFrame\n",
        "\n",
        "# 1. Define numeric features\n",
        "X_num = df[[\"Age\", \"Experience\"]]\n",
        "\n",
        "# 2. One-hot encode categorical features\n",
        "cat_cols = [\"Gender\", \"Education\", \"Job Title\", \"Country\", \"Race\"]\n",
        "ohe = OneHotEncoder(drop=\"first\", sparse_output=False)\n",
        "X_cat = pd.DataFrame(\n",
        "    ohe.fit_transform(df[cat_cols]),\n",
        "    columns=ohe.get_feature_names_out(cat_cols),\n",
        "    index=df.index\n",
        ")\n",
        "\n",
        "# 3. Combine into a single feature matrix\n",
        "X = pd.concat([X_num, X_cat], axis=1)\n",
        "\n",
        "# 4. Impute missing numeric values\n",
        "imp = SimpleImputer(strategy=\"median\")\n",
        "X_num_imputed = pd.DataFrame(\n",
        "    imp.fit_transform(X_num),\n",
        "    columns=X_num.columns,\n",
        "    index=df.index\n",
        ")\n",
        "\n",
        "# 5. Update X with the imputed numeric values\n",
        "X.update(X_num_imputed)"
      ],
      "metadata": {
        "id": "Cx14JrGJJ9n_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Normalisation and Standardisation**"
      ],
      "metadata": {
        "id": "ZpfIg2dZT7O_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
        "y = df[\"Salary\"]\n"
      ],
      "metadata": {
        "id": "5O-vVCE9KV6s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Spliting Data in to Train and Test**"
      ],
      "metadata": {
        "id": "imdWAZSXUFur"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.2, random_state=42\n",
        ")\n"
      ],
      "metadata": {
        "id": "Aztb9GRRLIC2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna\n",
        "import optuna\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Optuna objective function\n",
        "def objective(trial):\n",
        "    C = trial.suggest_loguniform('C', 1e-2, 1e3)\n",
        "    epsilon = trial.suggest_loguniform('epsilon', 1e-2, 10)\n",
        "    gamma = trial.suggest_categorical('gamma', ['scale', 'auto'])\n",
        "\n",
        "    svr = SVR(kernel='rbf', C=C, epsilon=epsilon, gamma=gamma)\n",
        "    model = make_pipeline(StandardScaler(), svr)\n",
        "\n",
        "    score = cross_val_score(model, X_train, y_train, cv=2, scoring='neg_mean_squared_error')\n",
        "    return -score.mean()\n",
        "\n",
        "# Run optimization\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=50)\n",
        "\n",
        "# Best model training\n",
        "best_params = study.best_trial.params\n",
        "print(\"Best params from Optuna:\", best_params)\n",
        "\n",
        "best_model = make_pipeline(StandardScaler(), SVR(**best_params))\n",
        "best_model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate\n",
        "y_pred = best_model.predict(X_test)\n",
        "print(\"Test MSE:\", mean_squared_error(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "HG5S97R0u9xW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Evaluation**"
      ],
      "metadata": {
        "id": "3_vL6wAdUUF2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.svm import SVR\n",
        "# from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# # 9.1 Hyperparameter grid\n",
        "# param_grid = {\n",
        "#     \"C\": [1, 10, 100],\n",
        "#     \"epsilon\": [0.1, 1, 5],\n",
        "#     \"gamma\": [\"scale\", \"auto\"]\n",
        "# }\n",
        "\n",
        "# # 9.2 Grid search on SVR\n",
        "# svr = SVR(kernel=\"rbf\")\n",
        "# grid = GridSearchCV(svr, param_grid, cv=5, scoring=\"neg_mean_squared_error\", n_jobs=-1)\n",
        "# grid.fit(X_train, y_train)\n",
        "\n",
        "# print(\"Best params:\", grid.best_params_)\n",
        "# model = grid.best_estimator_\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ####################\n",
        "# param_grid = {\n",
        "#     \"C\": [0.1, 1, 10, 100, 1000],\n",
        "#     \"epsilon\": [0.01, 0.1, 0.5, 1, 5, 10],\n",
        "#     \"gamma\": [\"scale\", \"auto\", 0.001, 0.01, 0.1, 1]\n",
        "# }\n",
        "\n",
        "# # 9.2 Grid search on SVR\n",
        "# svr = SVR(kernel=\"rbf\")\n",
        "# grid = GridSearchCV(svr, param_grid, cv=2, scoring=\"neg_mean_squared_error\", n_jobs=-1, verbose=2)\n",
        "# grid.fit(X_train, y_train)\n",
        "\n",
        "# print(\"Best params:\", grid.best_params_)\n",
        "# model = grid.best_estimator_\n",
        "# #########################\n",
        "\n",
        "# from sklearn.model_selection import RandomizedSearchCV\n",
        "# from scipy.stats import uniform\n",
        "\n",
        "# param_dist = {\n",
        "#     \"C\": uniform(0.1, 1000),\n",
        "#     \"epsilon\": uniform(0.01, 10),\n",
        "#     \"gamma\": [\"scale\", \"auto\"]\n",
        "# }\n",
        "\n",
        "# svr = SVR(kernel=\"rbf\")\n",
        "# rand_search = RandomizedSearchCV(svr, param_distributions=param_dist, n_iter=50,cv=5, scoring=\"neg_mean_squared_error\", n_jobs=-1, random_state=42)\n",
        "# rand_search.fit(X_train, y_train)\n",
        "# print(\"Best params:\", rand_search.best_params_)\n"
      ],
      "metadata": {
        "id": "fCpNbceOLKyv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# y_pred = model.predict(X_test)\n",
        "# print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
        "# print(\"R²:\", r2_score(y_test, y_pred))\n",
        "\n",
        "# # 10.1 Plot predictions vs. actual\n",
        "# plt.scatter(y_test, y_pred, alpha=0.6)\n",
        "# plt.plot([y.min(), y.max()], [y.min(), y.max()], \"r--\")\n",
        "# plt.xlabel(\"Actual Salary\")\n",
        "# plt.ylabel(\"Predicted Salary\")\n",
        "# plt.title(\"SVR: Actual vs Predicted\")\n",
        "# plt.show()\n"
      ],
      "metadata": {
        "id": "OMFv2vnbMS-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Result Visualization**"
      ],
      "metadata": {
        "id": "yFHmtHgDqb3I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVR\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Using only Years of Experience for visualization\n",
        "X_vis = df[[\"Experience\"]].values\n",
        "y_vis = df[\"Salary\"].values.reshape(-1, 1)\n",
        "\n",
        "# Feature scaling\n",
        "sc_X = StandardScaler()\n",
        "sc_y = StandardScaler()\n",
        "\n",
        "X_scaled = sc_X.fit_transform(X_vis)\n",
        "y_scaled = sc_y.fit_transform(y_vis).ravel()\n",
        "\n",
        "# SVR model\n",
        "regressor = SVR(kernel='rbf')\n",
        "regressor.fit(X_scaled, y_scaled)\n",
        "\n",
        "# High-res grid for smooth curve\n",
        "X_grid = np.arange(min(X_scaled), max(X_scaled), 0.01).reshape(-1, 1)\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(sc_X.inverse_transform(X_scaled), sc_y.inverse_transform(y_scaled.reshape(-1, 1)), color='red')\n",
        "plt.plot(sc_X.inverse_transform(X_grid), sc_y.inverse_transform(regressor.predict(X_grid).reshape(-1, 1)), color='blue')\n",
        "plt.title('SVR Model - Salary vs. Experience')\n",
        "plt.xlabel('Years of Experience')\n",
        "plt.ylabel('Salary')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "AyNV7UmtON0f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OOmj-vwgQHW4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}